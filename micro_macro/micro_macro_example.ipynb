{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from make_dir import mkdir\n",
    "from load_yaml import get_yaml\n",
    "\n",
    "import models.micro_macro_net as solutions\n",
    "import equations.micro_macro_eqn as equation\n",
    "\n",
    "from micro_macro_dataset import Sampler\n",
    "import micro_macro_solver as solver \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "current_path = os.path.abspath(\".\")\n",
    "yaml_path = os.path.join(current_path, \"micro_macro.yaml\")\n",
    "Config = get_yaml(yaml_path)\n",
    "\n",
    "# load reference data\n",
    "absolute_path = os.path.abspath(\"..\")\n",
    "ref_path = os.path.join(absolute_path, \"data/ref_kn1e-8.npz\")\n",
    "ref_rho = torch.Tensor(np.load(ref_path)[\"macro_frames\"]).to('cpu').reshape((-1, 1)) # shape: (100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dimension = Config[\"physical_config\"][\"time_dimension\"]\n",
    "space_dimension = Config[\"physical_config\"][\"space_dimension\"]\n",
    "velocity_dimension = Config[\"physical_config\"][\"velocity_dimension\"]\n",
    "rho_d_in = time_dimension + space_dimension\n",
    "layers_rho = Config[\"model_config\"][\"units_rho\"]\n",
    "g_d_in = time_dimension + space_dimension + velocity_dimension\n",
    "layers_g = Config[\"model_config\"][\"units_g\"]\n",
    "\n",
    "# build neural networks for rho, g\n",
    "Model_rho = \"solutions.Model_rho_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_rho = eval(Model_rho)\n",
    "\n",
    "model_rho = Model_rho(input_size = rho_d_in, layers = layers_rho, output_size = 1)\n",
    "\n",
    "Model_g = \"solutions.Model_g_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_g = eval(Model_g)\n",
    "\n",
    "model_g = Model_g(input_size = g_d_in, layers = layers_g, output_size = 1)\n",
    "\n",
    "device_ids = Config[\"model_config\"][\"device_ids\"]\n",
    "device = torch.device(\"cuda:{:d}\".format(device_ids[0]) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_rho = nn.DataParallel(model_rho, device_ids = device_ids)    \n",
    "    model_g = nn.DataParallel(model_g, device_ids = device_ids)\n",
    "    \n",
    "model_rho.to(device)\n",
    "model_g.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of paramerters\n",
    "rho_param_num = sum(neural.numel() for neural in model_rho.parameters())\n",
    "g_param_num = sum(neural.numel() for neural in model_g.parameters())\n",
    "print(\"Number of paramerters for networks u is: {:6d} and {:6d}. \".format(rho_param_num, g_param_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.Xavier_initi(model_rho)\n",
    "solutions.Xavier_initi(model_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and learning rate decay\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_rho.parameters()},\n",
    "    {'params': model_g.parameters()},\n",
    "],  lr=Config[\"model_config\"][\"lr\"])\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, Config[\"model_config\"][\"stage_num\"], Config[\"model_config\"][\"decay_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sol = model_rho, model_g\n",
    "eqn = equation.MicroMacro(config = Config, sol = Sol)\n",
    "\n",
    "Iter = Config[\"model_config\"][\"iterations\"] \n",
    "regularizers = Config[\"model_config\"][\"regularizers\"]\n",
    "\n",
    "loss_record, error_record = np.array([[]]).T, np.array([[]]*1).T\n",
    "\n",
    "mkdir(file_dir = \"./model_saved\")\n",
    "mkdir(file_dir = \"./record\")\n",
    "mkdir(file_dir = \"./figure\")\n",
    "\n",
    "time_start = time.time()\n",
    "print('Begin training.')\n",
    "print('')\n",
    "for it in range(Iter):\n",
    "    \n",
    "    sampler = Sampler(Config)\n",
    "    trainloader = [sampler.interior(), sampler.boundary(), sampler.initial()]\n",
    "        \n",
    "    risk, error = solver.train_step(sol = Sol,\n",
    "                                    trainloader = trainloader, \n",
    "                                    equation = eqn,  \n",
    "                                    regularizers = regularizers,\n",
    "                                    optimizer = optimizer, \n",
    "                                    scheduler = scheduler,\n",
    "                                    ref = ref_rho)\n",
    "    \n",
    "    loss = risk[\"total_loss\"]\n",
    "    res_micro_eqn = risk[\"micro\"]\n",
    "    res_macro_eqn = risk[\"macro\"]\n",
    "    res_bc_f = risk[\"bc_f\"]\n",
    "    res_ic_f = risk[\"ic_f\"]\n",
    "    error = error[\"error\"] \n",
    "\n",
    "    error = np.array(error, dtype=float).reshape(1, -1)\n",
    "    loss_record = np.concatenate((loss_record, loss*np.ones((1, 1))), axis=0)\n",
    "    error_record = np.concatenate((error_record, error), axis=0)\n",
    "\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "    \n",
    "        print(\"[Iter: {:6d}/{:6d} - lr: {:.2e} and Loss: {:.2e}]\".format(it + 1, Iter, lr, loss))\n",
    "        print(\"[Error for density: {:.2e}]\".format(float(error[:, 0])))\n",
    "        print(\"[Eqn micro: {:.2e}, macro: {:.2e}, Boundary: {:.2e}, Initial: {:.2e}]\".format(res_micro_eqn, res_macro_eqn, res_bc_f, res_ic_f))\n",
    "\n",
    "        \n",
    "    if np.max(error) < 1e-3:\n",
    "        print(\"Iteration step: \", it)\n",
    "        break\n",
    "\n",
    "np.savez(\"./record/result.npz\",\n",
    "         loss=loss_record,\n",
    "         error=error_record[:, 0])\n",
    "\n",
    "solutions.save_param(model_rho, path = './model_saved/model_rho_params.pkl')\n",
    "solutions.save_param(model_g, path = './model_saved/model_g_params.pkl')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Finished training.\")\n",
    "time_end = time.time()\n",
    "print(\"Total time is: {:.2e}\".format(time_end - time_start), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "solutions.load_param(model_rho, './model_saved/model_rho_params.pkl')\n",
    "solutions.load_param(model_g, './model_saved/model_g_params.pkl')\n",
    "\n",
    "Sol = [model_rho, model_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab370f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 100\n",
    "ref_x = torch.Tensor(np.linspace(0.005, 0.995, data_size).reshape((data_size, 1))).to(device)\n",
    "ref_t = 0.1 * torch.ones((ref_x.shape[0], 1)).to(device)\n",
    "approx_rho = eqn.rho(sol=Sol, inputs=[ref_t, ref_x]).cpu().detach().numpy()\n",
    "\n",
    "plt.style.use(\"seaborn-dark\") \n",
    "fig = plt.figure()\n",
    "plt.plot(ref_x.cpu().detach().numpy() , approx_rho, color = 'r', marker = 'x', linewidth = 0.0, markersize = 5, markevery = 2, label = 'APNN(t = 0.1)')\n",
    "plt.plot(ref_x.cpu().detach().numpy() , ref_rho, color = 'k', linewidth = 1.0, markersize = 10, label = 'Ref(t = 0.1)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(r\"x\")\n",
    "plt.ylabel(r\"$\\rho$\")\n",
    "plt.title(r\"$\\rho,$ ref at $t = 1$\")\n",
    "# plt.savefig('./figure/example_micro_macro.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # jupyter notebook to python\n",
    "# try:   \n",
    "#     !jupyter nbconvert --to python example.ipynb\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f552e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2883023b7651cb32604f918e2ac667f11b21b4a946c1f00e94d9e45b943bca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
