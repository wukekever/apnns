{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from make_dir import mkdir\n",
    "from load_yaml import get_yaml\n",
    "\n",
    "import models.bgk_net as solutions\n",
    "import equations.bgk_eqn as equation\n",
    "\n",
    "from bgk_dataset import Sampler\n",
    "import bgk_solver as solver \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "current_path = os.path.abspath(\".\")\n",
    "yaml_path = os.path.join(current_path, \"bgk.yaml\")\n",
    "Config = get_yaml(yaml_path)\n",
    "\n",
    "# load reference data\n",
    "absolute_path = os.path.abspath(\"..\")\n",
    "ref_path = os.path.join(absolute_path, \"data/dirichlet_ref_kn1e0.npz\")\n",
    "ref = np.load(ref_path)\n",
    "time_freq = 1\n",
    "ref_rho = ref[\"density\"][::time_freq].astype(\"float32\").reshape(-1, 1) # shape: (100, 1)\n",
    "ref_momentum = ref[\"momentum\"][::time_freq].astype(\"float32\").reshape(-1, 1)\n",
    "ref_energy = ref[\"energy\"][::time_freq].astype(\"float32\").reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dimension = Config[\"physical_config\"][\"time_dimension\"]\n",
    "space_dimension = Config[\"physical_config\"][\"space_dimension\"]\n",
    "velocity_dimension = Config[\"physical_config\"][\"velocity_dimension\"]\n",
    "\n",
    "d1_in = time_dimension + space_dimension + velocity_dimension\n",
    "d2_in = time_dimension + space_dimension\n",
    "\n",
    "layers_f = Config[\"model_config\"][\"units_f\"]\n",
    "layers_rho = Config[\"model_config\"][\"units_rho\"]\n",
    "layers_u = Config[\"model_config\"][\"units_u\"]\n",
    "layers_T = Config[\"model_config\"][\"units_T\"]\n",
    "\n",
    "# build neural networks for f, rho, u, T\n",
    "Model_f = \"solutions.Model_f_\" +     \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_f = eval(Model_f)\n",
    "\n",
    "Model_rho = \"solutions.Model_rho_\" +     \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_rho = eval(Model_rho)\n",
    "\n",
    "Model_u = \"solutions.Model_u_\" +     \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_u = eval(Model_u)\n",
    "\n",
    "Model_T = \"solutions.Model_T_\" +     \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_T = eval(Model_T)\n",
    "\n",
    "model_f = Model_f(input_size = d1_in, layers = layers_f, output_size = 1)\n",
    "model_rho = Model_rho(input_size = d2_in, layers = layers_rho, output_size = 1)\n",
    "model_u = Model_u(input_size = d2_in, layers = layers_u, output_size = 1)\n",
    "model_T = Model_T(input_size = d2_in, layers = layers_T, output_size = 1)\n",
    "\n",
    "device_ids = Config[\"model_config\"][\"device_ids\"]\n",
    "device = torch.device(\"cuda:{:d}\".format(device_ids[0]) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:    \n",
    "    model_f = nn.DataParallel(model_f, device_ids = device_ids)\n",
    "    model_rho = nn.DataParallel(model_rho, device_ids = device_ids)\n",
    "    model_u = nn.DataParallel(model_u, device_ids = device_ids)\n",
    "    model_T = nn.DataParallel(model_T, device_ids = device_ids)\n",
    "    \n",
    "model_f.to(device)\n",
    "model_rho.to(device)\n",
    "model_u.to(device)\n",
    "model_T.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of paramerters\n",
    "param_num_1 = sum(neural.numel() for neural in model_f.parameters())\n",
    "param_num_2 = sum(neural.numel() for neural in model_rho.parameters())\n",
    "param_num_3 = sum(neural.numel() for neural in model_u.parameters())\n",
    "param_num_4 = sum(neural.numel() for neural in model_T.parameters())\n",
    "print(\"Number of paramerters for networks f, rho, u, T is: {:6d}, {:6d}, {:6d}, {:6d}. \".format(\n",
    "    param_num_1, param_num_2, param_num_3, param_num_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.Xavier_initi(model_f)\n",
    "solutions.Xavier_initi(model_rho)\n",
    "solutions.Xavier_initi(model_u)\n",
    "solutions.Xavier_initi(model_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "def plot(iter):\n",
    "    xmin = Config[\"physical_config\"][\"x_range\"][0]\n",
    "    xmax = Config[\"physical_config\"][\"x_range\"][1]\n",
    "    tmax = Config[\"physical_config\"][\"t_range\"][1]\n",
    "\n",
    "    nx = 100\n",
    "    dx = float(xmax - xmin) / nx\n",
    "    ref_x = torch.arange(xmin + dx / 2, xmax + dx / 2, dx).reshape((-1, 1))\n",
    "    ref_t = tmax * torch.ones((nx, 1))\n",
    "\n",
    "    model_rho, model_u, model_T = Sol[1:]\n",
    "    rho_approx = model_rho(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "    u_approx = model_u(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "    T_approx = model_T(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "    approx_density = rho_approx\n",
    "    approx_momentum = rho_approx * u_approx\n",
    "    approx_energy = 0.5 * rho_approx * (u_approx**2 + T_approx)\n",
    "\n",
    "    plt.plot(ref_x, ref_rho, \"r\", label = \"density\")\n",
    "    plt.plot(ref_x, ref_momentum, \"k\", label = \"momentum\")\n",
    "    plt.plot(ref_x, ref_energy, \"g\", label = \"energy\")\n",
    "\n",
    "    plt.plot(ref_x, approx_density, \"r*\", markevery= 4, label = \"approx density\")\n",
    "    plt.plot(ref_x, approx_momentum, \"k+\", markevery= 4, label = \"approx momentum\")\n",
    "    plt.plot(ref_x, approx_energy, \"gx\", markevery= 4, label = \"approx energy\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"macro\")\n",
    "    plt.title(\"Approximate density, momentum, energy and reference solutions\")\n",
    "    plt.savefig(\"./figure/solution_iter_{:d}.pdf\".format(iter))\n",
    "    # plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and learning rate decay\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_f.parameters()},\n",
    "    {'params': model_rho.parameters()},\n",
    "    {'params': model_u.parameters()},\n",
    "    {'params': model_T.parameters()}\n",
    "],  lr=Config[\"model_config\"][\"lr\"])\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, Config[\"model_config\"][\"stage_num\"], Config[\"model_config\"][\"decay_rate\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sol = [model_f, model_rho, model_u, model_T]\n",
    "eqn = equation.BGK(config = Config, sol = Sol)\n",
    "\n",
    "Iter = Config[\"model_config\"][\"iterations\"] \n",
    "regularizers = Config[\"model_config\"][\"regularizers\"]\n",
    "\n",
    "loss_record, error_record = np.array([[]]).T, np.array([[]]*3).T\n",
    "\n",
    "mkdir(file_dir = \"./model_saved\")\n",
    "mkdir(file_dir = \"./record\")\n",
    "mkdir(file_dir = \"./figure\")\n",
    "\n",
    "time_start = time.time()\n",
    "print('Begin training.')\n",
    "print('')\n",
    "for it in range(Iter):\n",
    "    \n",
    "    sampler = Sampler(Config)\n",
    "    trainloader = [sampler.interior(), sampler.boundary(), sampler.initial()]\n",
    "        \n",
    "    risk, error = solver.train_step(sol = Sol,\n",
    "                                    trainloader = trainloader, \n",
    "                                    equation = eqn,  \n",
    "                                    regularizers = regularizers,\n",
    "                                    optimizer = optimizer, \n",
    "                                    scheduler = scheduler,\n",
    "                                    ref = ref)\n",
    "    \n",
    "    loss = risk[\"total_loss\"]\n",
    "    res_bgk_eqn = risk[\"bgk\"]\n",
    "    res_conservation_eqn_1 = risk[\"conservation\"][0]\n",
    "    res_conservation_eqn_2 = risk[\"conservation\"][1]\n",
    "    res_conservation_eqn_3 = risk[\"conservation\"][2]\n",
    "\n",
    "    res_relaxation_eqn_1 = risk[\"relaxation\"][0]\n",
    "    res_relaxation_eqn_2 = risk[\"relaxation\"][1]\n",
    "    res_relaxation_eqn_3 = risk[\"relaxation\"][2]\n",
    "\n",
    "    res_bc_rho = risk[\"bc_rho\"]\n",
    "    res_bc_u = risk[\"bc_u\"]\n",
    "    res_bc_T = risk[\"bc_T\"]\n",
    "\n",
    "    res_ic_rho = risk[\"ic_rho\"]\n",
    "    res_ic_u = risk[\"ic_u\"]\n",
    "    res_ic_T = risk[\"ic_T\"]\n",
    "    res_ic_f = risk[\"ic_f\"]\n",
    "\n",
    "    error = error[\"macro_error\"] \n",
    "\n",
    "    error = np.array(error, dtype=float).reshape(1, -1)\n",
    "    loss_record = np.concatenate((loss_record, loss*np.ones((1, 1))), axis=0)\n",
    "    error_record = np.concatenate((error_record, error), axis=0)\n",
    "\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "    \n",
    "        print(\"[Iter: {:6d}/{:6d} - lr: {:.2e} and Loss: {:.2e}]\".format(it + 1, Iter, lr, loss))\n",
    "        print(\n",
    "            \"[Error for density: {:.2e} - momentum: {:.2e} - energy: {:.2e}]\".format(\n",
    "                float(error[:, 0]), float(error[:, 1]), float(error[:, 2])\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"[BGK eqn: {:.2e} and Conservation - density: {:.2e} - momentum: {:.2e} - energy: {:.2e}]\".format(\n",
    "                res_bgk_eqn,\n",
    "                res_conservation_eqn_1, \n",
    "                res_conservation_eqn_2, \n",
    "                res_conservation_eqn_3\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"[Relaxation - rho: {:.2e} - u: {:.2e} - T: {:.2e}]\".format(\n",
    "                res_relaxation_eqn_1, \n",
    "                res_relaxation_eqn_2, \n",
    "                res_relaxation_eqn_3\n",
    "            )\n",
    "        )\n",
    "        # print(\n",
    "        #     \"[Boundary - rho: {:.2e} - u: {:.2e} - T: {:.2e}]\".format(\n",
    "        #         res_bc_rho, res_bc_u, res_bc_T\n",
    "        #     )\n",
    "        # ) \n",
    "        print(\n",
    "            \"[Initial - rho: {:.2e} - u: {:.2e} - T: {:.2e} - f: {:.2e}]\".format(\n",
    "                res_ic_rho, res_ic_u, res_ic_T, res_ic_f\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    if (it + 1) % 100 == 0:\n",
    "        plot(iter = it + 1) \n",
    "        \n",
    "    if np.max(error) < 1e-2:\n",
    "        print(\"Iteration step: \", it)\n",
    "        break\n",
    "\n",
    "np.savez(\"./record/result.npz\",\n",
    "         loss=loss_record,\n",
    "         error_rho=error_record[:, 0],\n",
    "         error_momentum=error_record[:, 1],\n",
    "         error_energy=error_record[:, 2])\n",
    "\n",
    "solutions.save_param(model_f, path = './model_saved/model_f_params.pkl')\n",
    "solutions.save_param(model_rho, path = './model_saved/model_rho_params.pkl')\n",
    "solutions.save_param(model_u, path = './model_saved/model_u_params.pkl')\n",
    "solutions.save_param(model_T, path = './model_saved/model_T_params.pkl')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Finished training.\")\n",
    "time_end = time.time()\n",
    "print(\"Total time is: {:.2e}\".format(time_end - time_start), \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "current_path = os.path.abspath(\".\")\n",
    "yaml_path = os.path.join(current_path, \"bgk_finetune.yaml\")\n",
    "Config = get_yaml(yaml_path)\n",
    "\n",
    "# Set optimizer and learning rate decay\n",
    "# freeze model rho parameters\n",
    "# optimizer = optim.Adam([\n",
    "#     {'params': model_f.parameters()},\n",
    "#     {'params': model_u.parameters()},\n",
    "#     {'params': model_T.parameters()}\n",
    "# ],  lr=Config[\"model_config\"][\"lr\"])\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_f.parameters()},\n",
    "    {'params': model_u.parameters()},\n",
    "    {'params': model_T.parameters()}\n",
    "],  lr=0.001)\n",
    "\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, Config[\"model_config\"][\"stage_num\"], Config[\"model_config\"][\"decay_rate\"])\n",
    "    \n",
    "Iter = Config[\"model_config\"][\"iterations\"] \n",
    "regularizers = Config[\"model_config\"][\"regularizers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(Iter):\n",
    "    \n",
    "    sampler = Sampler(Config)\n",
    "    trainloader = [sampler.interior(), sampler.boundary(), sampler.initial()]\n",
    "        \n",
    "    risk, error = solver.train_step(sol = Sol,\n",
    "                                    trainloader = trainloader, \n",
    "                                    equation = eqn,  \n",
    "                                    regularizers = regularizers,\n",
    "                                    optimizer = optimizer, \n",
    "                                    scheduler = scheduler,\n",
    "                                    ref = ref)\n",
    "    \n",
    "    loss = risk[\"total_loss\"]\n",
    "    res_bgk_eqn = risk[\"bgk\"]\n",
    "    res_conservation_eqn_1 = risk[\"conservation\"][0]\n",
    "    res_conservation_eqn_2 = risk[\"conservation\"][1]\n",
    "    res_conservation_eqn_3 = risk[\"conservation\"][2]\n",
    "\n",
    "    res_relaxation_eqn_1 = risk[\"relaxation\"][0]\n",
    "    res_relaxation_eqn_2 = risk[\"relaxation\"][1]\n",
    "    res_relaxation_eqn_3 = risk[\"relaxation\"][2]\n",
    "\n",
    "    res_bc_rho = risk[\"bc_rho\"]\n",
    "    res_bc_u = risk[\"bc_u\"]\n",
    "    res_bc_T = risk[\"bc_T\"]\n",
    "\n",
    "    res_ic_rho = risk[\"ic_rho\"]\n",
    "    res_ic_u = risk[\"ic_u\"]\n",
    "    res_ic_T = risk[\"ic_T\"]\n",
    "    res_ic_f = risk[\"ic_f\"]\n",
    "\n",
    "    error = error[\"macro_error\"] \n",
    "\n",
    "    error = np.array(error, dtype=float).reshape(1, -1)\n",
    "    loss_record = np.concatenate((loss_record, loss*np.ones((1, 1))), axis=0)\n",
    "    error_record = np.concatenate((error_record, error), axis=0)\n",
    "\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    if it % 1 == 0:\n",
    "    \n",
    "        print(\"[Iter: {:6d}/{:6d} - lr: {:.2e} and Loss: {:.2e}]\".format(it + 1, Iter, lr, loss))\n",
    "        print(\n",
    "            \"[Error for density: {:.2e} - momentum: {:.2e} - energy: {:.2e}]\".format(\n",
    "                float(error[:, 0]), float(error[:, 1]), float(error[:, 2])\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"[BGK eqn: {:.2e} and Conservation - density: {:.2e} - momentum: {:.2e} - energy: {:.2e}]\".format(\n",
    "                res_bgk_eqn,\n",
    "                res_conservation_eqn_1, \n",
    "                res_conservation_eqn_2, \n",
    "                res_conservation_eqn_3\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"[Relaxation - rho: {:.2e} - u: {:.2e} - T: {:.2e}]\".format(\n",
    "                res_relaxation_eqn_1, \n",
    "                res_relaxation_eqn_2, \n",
    "                res_relaxation_eqn_3\n",
    "            )\n",
    "        )\n",
    "        # print(\n",
    "        #     \"[Boundary - rho: {:.2e} - u: {:.2e} - T: {:.2e}]\".format(\n",
    "        #         res_bc_rho, res_bc_u, res_bc_T\n",
    "        #     )\n",
    "        # ) \n",
    "        print(\n",
    "            \"[Initial - rho: {:.2e} - u: {:.2e} - T: {:.2e} - f: {:.2e}]\".format(\n",
    "                res_ic_rho, res_ic_u, res_ic_T, res_ic_f\n",
    "            )\n",
    "        )\n",
    "       \n",
    "\n",
    "solutions.save_param(model_f, path = './model_saved/model_f_params.pkl')\n",
    "solutions.save_param(model_rho, path = './model_saved/model_rho_params.pkl')\n",
    "solutions.save_param(model_u, path = './model_saved/model_u_params.pkl')\n",
    "solutions.save_param(model_T, path = './model_saved/model_T_params.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# solutions.load_param(model_f, './model_saved/model_f_params.pkl')\n",
    "# solutions.load_param(model_rho, './model_saved/model_rho_params.pkl')\n",
    "# solutions.load_param(model_u, './model_saved/model_u_params.pkl')\n",
    "# solutions.load_param(model_T, './model_saved/model_T_params.pkl')\n",
    "\n",
    "Sol = [model_f, model_rho, model_u, model_T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = Config[\"physical_config\"][\"x_range\"][0]\n",
    "xmax = Config[\"physical_config\"][\"x_range\"][1]\n",
    "tmax = Config[\"physical_config\"][\"t_range\"][1]\n",
    "\n",
    "nx = 100\n",
    "dx = float(xmax - xmin) / nx\n",
    "ref_x = torch.arange(xmin + dx / 2, xmax + dx / 2, dx).reshape((-1, 1))\n",
    "ref_t = tmax * torch.ones((nx, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rho, model_u, model_T = Sol[1:]\n",
    "rho_approx = model_rho(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "u_approx = model_u(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "T_approx = model_T(torch.Tensor(torch.cat([ref_t, ref_x], axis=-1)).to(device)).cpu().detach().numpy()\n",
    "approx_density = rho_approx\n",
    "approx_momentum = rho_approx * u_approx\n",
    "approx_energy = 0.5 * rho_approx * (u_approx**2 + T_approx)\n",
    "\n",
    "plt.plot(ref_x, ref_rho, \"r\", label=\"density\")\n",
    "plt.plot(ref_x, ref_momentum, \"k\", label=\"momentum\")\n",
    "plt.plot(ref_x, ref_energy, \"g\", label=\"energy\")\n",
    "\n",
    "plt.plot(ref_x, approx_density, \"r*\", markevery=4, label=\"approx density\")\n",
    "plt.plot(ref_x, approx_momentum, \"k+\", markevery=4, label=\"approx momentum\")\n",
    "plt.plot(ref_x, approx_energy, \"gx\", markevery=4, label=\"approx energy\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"macro\")\n",
    "plt.title(\"Approximate density, momentum, energy and reference solutions\")\n",
    "plt.savefig(\"./figure/solution_macro.pdf\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_op(model, t_x, vwquads):\n",
    "        tx = torch.cat(t_x, -1)[:, None, :]\n",
    "        v, w = vwquads\n",
    "        mult_fact = torch.ones((tx.shape[0], v.shape[0], 1))\n",
    "        fn = model(torch.cat([tx * mult_fact, v[..., None] * mult_fact], -1)).cpu()\n",
    "        return torch.sum(fn * w[..., None], axis=-2)\n",
    "\n",
    "v, w = np.polynomial.legendre.leggauss(32)\n",
    "v = 0.5 * (v + 1.0) * 20 - 10\n",
    "w = 0.5 * 20 * w\n",
    "vquads = torch.Tensor(v)\n",
    "wquads = torch.Tensor(w)\n",
    "\n",
    "model_f = Sol[0]\n",
    "avg_f_1 = average_op(model_f, [ref_t, ref_x], [vquads, wquads]).detach().numpy()\n",
    "approx_density = avg_f_1\n",
    "avg_f_2 = average_op(model_f, [ref_t, ref_x], [vquads, wquads * vquads]).detach().numpy()\n",
    "approx_momentum = avg_f_2\n",
    "avg_f_3 = average_op(model_f, [ref_t, ref_x], [vquads, wquads * vquads ** 2]).detach().numpy()\n",
    "approx_energy = 0.5 * avg_f_3\n",
    "\n",
    "plt.plot(ref_x, ref_rho, \"r\", label = \"density\")\n",
    "plt.plot(ref_x, ref_momentum, \"k\", label = \"momentum\")\n",
    "plt.plot(ref_x, ref_energy, \"g\", label = \"energy\")\n",
    "\n",
    "plt.plot(ref_x, approx_density, \"r*\", markevery= 4, label = r\"$<f>$\")\n",
    "plt.plot(ref_x, approx_momentum, \"k+\", markevery= 4, label = r\"$<fv>$\")\n",
    "plt.plot(ref_x, approx_energy, \"gx\", markevery= 4, label = r\"$\\frac{1}{2} <fv^2>$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"macro\")\n",
    "plt.title(\"Approximate integrals of f (density, momentum, energy) and reference solutions\")\n",
    "plt.savefig(\"./figure/solution_f.pdf\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2883023b7651cb32604f918e2ac667f11b21b4a946c1f00e94d9e45b943bca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
