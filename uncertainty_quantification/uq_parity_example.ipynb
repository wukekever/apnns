{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from make_dir import mkdir\n",
    "from load_yaml import get_yaml\n",
    "\n",
    "import models.uq_parity_net as solutions\n",
    "import equations.uq_parity_eqn as equation\n",
    "\n",
    "from uq_parity_dataset import Sampler\n",
    "import parity_solver as solver \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "current_path = os.path.abspath(\".\")\n",
    "yaml_path = os.path.join(current_path, \"uq_parity.yaml\")\n",
    "Config = get_yaml(yaml_path)\n",
    "\n",
    "# load reference data\n",
    "absolute_path = os.path.abspath(\"..\")\n",
    "ref_path = os.path.join(absolute_path, \"data/uq_simulation.npz\")\n",
    "rho_mean = torch.mean(torch.Tensor(np.load(ref_path)[\"macro_frames\"]), axis=0)\n",
    "\n",
    "ref_rho = rho_mean[-1, :].to('cpu').reshape((-1, 1)) # shape: (100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dimension = Config[\"physical_config\"][\"time_dimension\"]\n",
    "space_dimension = Config[\"physical_config\"][\"space_dimension\"]\n",
    "velocity_dimension = Config[\"physical_config\"][\"velocity_dimension\"]\n",
    "uq_dimension = Config[\"physical_config\"][\"uq_dimension\"]\n",
    "rho_d_in = time_dimension + space_dimension + uq_dimension\n",
    "layers_rho = Config[\"model_config\"][\"units_rho\"]\n",
    "rj_d_in = time_dimension + space_dimension + velocity_dimension  + uq_dimension\n",
    "layers_r = Config[\"model_config\"][\"units_r\"]\n",
    "layers_j = Config[\"model_config\"][\"units_j\"]\n",
    "\n",
    "# build neural networks for rho, g\n",
    "Model_rho = \"solutions.Model_rho_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_rho = eval(Model_rho)\n",
    "\n",
    "model_rho = Model_rho(input_size = rho_d_in, layers = layers_rho, output_size = 1)\n",
    "\n",
    "Model_r = \"solutions.Model_r_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_r = eval(Model_r)\n",
    "\n",
    "model_r = Model_r(input_size = rj_d_in, layers = layers_r, output_size = 1)\n",
    "\n",
    "Model_j = \"solutions.Model_j_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model_j = eval(Model_j)\n",
    "\n",
    "model_j = Model_j(input_size = rj_d_in, layers = layers_j, output_size = 1)\n",
    "\n",
    "device_ids = Config[\"model_config\"][\"device_ids\"]\n",
    "device = torch.device(\"cuda:{:d}\".format(device_ids[0]) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_rho = nn.DataParallel(model_rho, device_ids = device_ids)    \n",
    "    model_r = nn.DataParallel(model_r, device_ids = device_ids)\n",
    "    model_j = nn.DataParallel(model_j, device_ids = device_ids)\n",
    "\n",
    "    \n",
    "model_rho.to(device)\n",
    "model_r.to(device)\n",
    "model_j.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of paramerters\n",
    "rho_param_num = sum(neural.numel() for neural in model_rho.parameters())\n",
    "r_param_num = sum(neural.numel() for neural in model_r.parameters())\n",
    "j_param_num = sum(neural.numel() for neural in model_j.parameters())\n",
    "print(\"Number of paramerters for networks u is: {:6d}, {:6d} and {:6d}. \".format(rho_param_num, r_param_num, j_param_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.Xavier_initi(model_rho)\n",
    "solutions.Xavier_initi(model_r)\n",
    "solutions.Xavier_initi(model_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and learning rate decay\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_rho.parameters()},\n",
    "    {'params': model_r.parameters()},\n",
    "    {'params': model_j.parameters()},\n",
    "],  lr=Config[\"model_config\"][\"lr\"])\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, Config[\"model_config\"][\"stage_num\"], Config[\"model_config\"][\"decay_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sol = model_rho, model_r, model_j\n",
    "eqn = equation.Parity(config = Config, sol = Sol)\n",
    "\n",
    "Iter = Config[\"model_config\"][\"iterations\"] \n",
    "regularizers = Config[\"model_config\"][\"regularizers\"]\n",
    "\n",
    "loss_record, error_record = np.array([[]]).T, np.array([[]]*1).T\n",
    "\n",
    "mkdir(file_dir = \"./model_saved\")\n",
    "mkdir(file_dir = \"./record\")\n",
    "mkdir(file_dir = \"./figure\")\n",
    "\n",
    "time_start = time.time()\n",
    "print('Begin training.')\n",
    "print('')\n",
    "for it in range(Iter):\n",
    "    \n",
    "    sampler = Sampler(Config)\n",
    "    trainloader = [sampler.interior(), sampler.boundary(), sampler.initial()]\n",
    "        \n",
    "    risk, error = solver.train_step(sol = Sol,\n",
    "                                    trainloader = trainloader, \n",
    "                                    equation = eqn,  \n",
    "                                    regularizers = regularizers,\n",
    "                                    optimizer = optimizer, \n",
    "                                    scheduler = scheduler,\n",
    "                                    ref = ref_rho)\n",
    "    \n",
    "    loss = risk[\"total_loss\"]\n",
    "    res_parity_1_eqn = risk[\"parity_1\"]\n",
    "    res_parity_2_eqn = risk[\"parity_2\"]\n",
    "    res_claw_eqn = risk[\"conservation\"]\n",
    "    res_constraint_eqn = risk[\"soft_constraint\"]\n",
    "    res_bc_f = risk[\"bc_f\"]\n",
    "    res_ic_rho = risk[\"ic_rho\"]\n",
    "    res_ic_f = risk[\"ic_f\"]\n",
    "    error = error[\"error\"] \n",
    "\n",
    "    error = np.array(error, dtype=float).reshape(1, -1)\n",
    "    loss_record = np.concatenate((loss_record, loss*np.ones((1, 1))), axis=0)\n",
    "    error_record = np.concatenate((error_record, error), axis=0)\n",
    "\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    if it % 10 == 0:\n",
    "    \n",
    "        print(\"[Iter: {:6d}/{:6d} - lr: {:.2e} and Loss: {:.2e}]\".format(it + 1, Iter, lr, loss))\n",
    "        print(\"[Error for density: {:.2e}]\".format(float(error[:, 0])))\n",
    "        print(\"[Eqn parity_1: {:.2e}, parity_2: {:.2e}, claw: {:.2e}, constraint: {:.2e}]\".format(res_parity_1_eqn, res_parity_1_eqn, res_claw_eqn, res_constraint_eqn))\n",
    "        print(\"[Boundary: {:.2e}, Initial - rho {:.2e}, f {:.2e}]\".format(res_bc_f, res_ic_rho, res_ic_f))\n",
    "\n",
    "        \n",
    "    if np.max(error) < 5e-2:\n",
    "        print(\"Iteration step: \", it)\n",
    "        break\n",
    "\n",
    "np.savez(\"./record/result.npz\",\n",
    "         loss=loss_record,\n",
    "         error=error_record[:, 0])\n",
    "\n",
    "solutions.save_param(model_rho, path = './model_saved/model_rho_params.pkl')\n",
    "solutions.save_param(model_r, path = './model_saved/model_r_params.pkl')\n",
    "solutions.save_param(model_j, path = './model_saved/model_j_params.pkl')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Finished training.\")\n",
    "time_end = time.time()\n",
    "print(\"Total time is: {:.2e}\".format(time_end - time_start), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.load_param(model_rho, './model_saved/model_rho_params.pkl')\n",
    "solutions.load_param(model_r, './model_saved/model_r_params.pkl')\n",
    "solutions.load_param(model_j, './model_saved/model_j_params.pkl')\n",
    "\n",
    "Sol = [model_rho, model_r, model_j]# # load model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a99aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rho, model_r, model_j = Sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_rho_1 = rho_mean[-1, :].to('cpu').reshape((-1, 1)) # shape: (100, 1)\n",
    "ref_rho_2 = rho_mean[-501, :].to('cpu').reshape((-1, 1)) # shape: (100, 1)\n",
    "\n",
    "num_sim = 10**3\n",
    "nx = 100\n",
    "uq_dimension = Config[\"physical_config\"][\"uq_dimension\"]\n",
    "xmin, xmax = Config[\"physical_config\"][\"x_range\"]\n",
    "zmin, zmax = Config[\"physical_config\"][\"z_range\"]\n",
    "tmax = Config[\"physical_config\"][\"t_range\"][-1]\n",
    "ref_x = (torch.linspace(xmin, xmax, nx).reshape(-1, 1)).to(device)\n",
    "ref_xx = ref_x.to(\"cpu\")\n",
    "\n",
    "ref_t_1 = tmax * torch.ones((nx, 1)).to(device)\n",
    "ref_t_2 = tmax * torch.ones((nx, 1)).to(device) / 2\n",
    "\n",
    "\n",
    "ref_z = zmin + torch.rand((nx, num_sim, uq_dimension)).to(device) * (zmax - zmin)\n",
    "ref_x = ref_x[:,None,:] * torch.ones((ref_z.shape[0], ref_z.shape[1], 1)).to(device)\n",
    "\n",
    "ref_t1 = ref_t_1[:,None,:] * torch.ones((ref_z.shape[0], ref_z.shape[1], 1)).to(device)\n",
    "ref_t2 = ref_t_2[:,None,:] * torch.ones((ref_z.shape[0], ref_z.shape[1], 1)).to(device)\n",
    "\n",
    "ref_zt1x = torch.cat([ref_z, ref_t1, ref_x], -1)\n",
    "density_approx_1 = torch.mean((ref_t1*model_rho(ref_zt1x)).to(\"cpu\"), dim=-2).detach().numpy() # shape: (nx, 1)\n",
    "ref_zt2x = torch.cat([ref_z, ref_t2, ref_x], -1)\n",
    "density_approx_2 = torch.mean((ref_t2*model_rho(ref_zt2x)).to(\"cpu\"), dim=-2).detach().numpy() # shape: (nx, 1)\n",
    "\n",
    "plt.style.use(\"seaborn-dark\") \n",
    "fig = plt.figure()\n",
    "plt.plot(ref_xx, ref_rho_2, color = 'b', linewidth = 1.0, markersize = 5, label = 'Ref(t = 0.05)')\n",
    "plt.plot(ref_xx[2:], density_approx_2[2:], color = 'g', marker = 'x', linewidth = 0.0, markersize = 8, markevery = 4, label = 'APNNs(t = 0.05)')\n",
    "plt.plot(ref_xx, ref_rho_1, color = 'r', linewidth = 1.0, markersize = 5, label = 'Ref(t = 0.1)')\n",
    "plt.plot(ref_xx[2:], density_approx_1[2:], color = 'k', marker = '*', linewidth = 0.0, markersize = 8, markevery = 4, label = 'APNNs(t = 0.1)')\n",
    "plt.xlabel(r\"x\")\n",
    "plt.ylabel(r\"$\\rho$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('./figure/uq_1e-5.eps')\n",
    "plt.savefig('./figure/uq_1e-5.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # jupyter notebook to python\n",
    "# try:   \n",
    "#     !jupyter nbconvert --to python uq_parity_example.ipynb\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f552e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2883023b7651cb32604f918e2ac667f11b21b4a946c1f00e94d9e45b943bca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
